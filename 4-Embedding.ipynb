{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfe93dad",
   "metadata": {},
   "source": [
    "# 4.2.1 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8b41b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['오늘', '날씨', '구름']\n",
      "{'오늘': 0, '날씨': 1, '구름': 2}\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Komoran\n",
    "import numpy as np\n",
    "\n",
    "komoran = Komoran()\n",
    "text = \"오늘 날씨는 구름이 많아요\"\n",
    "\n",
    "# 명사만 추출\n",
    "nouns = komoran.nouns(text)\n",
    "print(nouns)\n",
    "\n",
    "# 단어 사전 구축 및 단어별 인덱스 부여\n",
    "dics = {}\n",
    "for word in nouns:\n",
    "    if word not in dics.keys():\n",
    "        dics[word] = len(dics)\n",
    "print(dics)\n",
    "\n",
    "# 원-핫 인코딩\n",
    "nb_classes = len(dics)\n",
    "targets = list(dics.values())\n",
    "one_hot_targets = np.eye(nb_classes)[targets]\n",
    "print(one_hot_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6a2f70",
   "metadata": {},
   "source": [
    "# 4.2.2 희소 표현과 분산 표현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c32cf6",
   "metadata": {},
   "source": [
    "# 4.2.3 Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbca366b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) 말뭉치 데이터 읽기 시작\n",
      "200000\n",
      "1) 말뭉치 데이터 읽기 완료:  0.5440161228179932\n",
      "2) 형태소에서 명사만 추출 시작\n",
      "2) 형태소에서 명사만 추출 완료:  85.18547296524048\n",
      "3) Word2Vec 모델 학습 시작\n",
      "3) Word2Vec 모델 학습 완료:  104.20827007293701\n",
      "4) 학습된 모델 저장 시작\n",
      "4) 학습된 모델 저장 완료:  104.28915309906006\n",
      "corpus_count:  200000\n",
      "corpus_total_words:  1076896\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from konlpy.tag import Komoran\n",
    "import time\n",
    "\n",
    "# 네이버 영화 리뷰 데이터 읽어옴\n",
    "def read_review_data(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = [line.split('\\t') for line in f.read().splitlines()]\n",
    "        data = data[1:] # 헤더 제거\n",
    "    return data\n",
    "\n",
    "# 학습 시간 측정 시작\n",
    "start = time.time()\n",
    "\n",
    "# 리뷰 파일 읽어오기\n",
    "print('1) 말뭉치 데이터 읽기 시작')\n",
    "review_data = read_review_data('./ratings.txt')\n",
    "print(len(review_data)) # 리뷰 데이터 전체 개수\n",
    "print('1) 말뭉치 데이터 읽기 완료: ', time.time()-start)\n",
    "\n",
    "# 문장 단위로 명사만 추출해 학습 입력 데이터로 만듦\n",
    "print('2) 형태소에서 명사만 추출 시작')\n",
    "komoran = Komoran()\n",
    "docs = [komoran.nouns(sentence[1]) for sentence in review_data]\n",
    "print('2) 형태소에서 명사만 추출 완료: ', time.time()-start)\n",
    "\n",
    "# Word2Vec 모델 학습\n",
    "print('3) Word2Vec 모델 학습 시작')\n",
    "model = Word2Vec(sentences=docs, vector_size=200, window=4, hs=1, min_count=2, sg=1)\n",
    "print('3) Word2Vec 모델 학습 완료: ', time.time()-start)\n",
    "\n",
    "# 모델 저장\n",
    "print('4) 학습된 모델 저장 시작')\n",
    "model.save('nvmc.model')\n",
    "print('4) 학습된 모델 저장 완료: ', time.time()-start)\n",
    "\n",
    "# 학습된 말뭉치 수, 코퍼스 내 전체 단어 수\n",
    "print(\"corpus_count: \", model.corpus_count)\n",
    "print(\"corpus_total_words: \", model.corpus_total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa17f98",
   "metadata": {},
   "source": [
    "- sentences: Word2Vec 모델 학습에 필요한 문장 데이터. Word2Vec 모델의 입력값으로 사용됨\n",
    "- vector_size: 단어 임베딩 벡터의 차원 (크기)\n",
    "- window: 주변 단어 윈도우의 크기\n",
    "- hs: 1(모델학습에 softmax 사용), 0(negative 옵션 값이 0이 아닐 때 음수 샘플링으로 사용)\n",
    "- min_count: 단어 최소 빈도수 제한 (tjfwjdehls min_count 빈도수 이하의 단어들은 학습하지 않음)\n",
    "- sg: 0(CBOW 모델), 1(skip-gram 모델)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "110a2bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus_total_words:  1076896\n",
      "사랑:  [-6.47868961e-02 -5.15041411e-01  1.84044376e-01 -2.70353258e-01\n",
      "  2.10005179e-01 -7.28060752e-02  5.51567078e-02  1.71588123e-01\n",
      " -2.54164226e-02 -9.50366780e-02 -4.62177962e-01  2.48968467e-01\n",
      "  6.77067637e-02 -1.15221396e-01 -1.67074159e-01  2.59793609e-01\n",
      " -1.54248610e-01  2.61751637e-02 -9.80559662e-02 -2.05659956e-01\n",
      "  1.48594096e-01  1.40902817e-01 -2.01088369e-01  2.12129846e-01\n",
      " -2.77419090e-01  9.35066566e-02  2.02679023e-01 -1.95244282e-01\n",
      " -1.31147623e-01  2.09806591e-01  7.06647336e-02  3.23556550e-02\n",
      "  1.14561051e-01 -1.87904418e-01  1.61628217e-01 -1.71363165e-04\n",
      "  1.23991847e-01 -3.19565763e-03 -4.57614474e-02 -1.28738582e-01\n",
      " -1.18259050e-01  1.70185506e-01 -1.37026757e-01 -1.84761196e-01\n",
      "  8.44365656e-02  1.96666703e-01 -3.47218752e-01  4.45370227e-02\n",
      "  1.17285505e-01  5.21596372e-02  3.15069914e-01 -8.34720656e-02\n",
      " -1.53974906e-01 -2.46060677e-02  4.47047621e-01  1.56436771e-01\n",
      "  2.77648658e-01 -2.12821007e-01  1.50535792e-01 -9.72119421e-02\n",
      "  3.85853350e-02  1.13505021e-01 -3.33653986e-01  1.00943089e-01\n",
      " -2.51790658e-02 -1.29851669e-01 -2.42681056e-01  8.01348165e-02\n",
      "  9.97022688e-02  4.74240839e-01 -2.41539657e-01 -3.06860119e-01\n",
      "  2.63652235e-01  4.46629934e-02  8.67481530e-02  3.28006372e-02\n",
      "  1.92520276e-01 -1.41828999e-01 -4.07523423e-01  1.03392191e-01\n",
      "  9.09467489e-02  1.00724973e-01  1.07019663e-01  2.67056853e-01\n",
      " -2.89638102e-01  2.53930449e-01  3.20422947e-02  1.16946302e-01\n",
      " -9.26060453e-02  6.55640662e-02  7.78229609e-02  1.72486901e-01\n",
      "  9.08787698e-02 -1.27326250e-01  5.34412682e-01  1.42497927e-01\n",
      "  1.05290517e-01  5.75202741e-02 -2.93851160e-02 -2.17221931e-01\n",
      " -1.73759043e-01  3.58575225e-01  2.29903013e-01  4.24171150e-01\n",
      "  7.61884004e-02 -3.28493595e-01  1.31606013e-01  2.36316055e-01\n",
      "  1.84238609e-02 -5.16016722e-01  1.78942293e-01 -2.72175372e-01\n",
      "  1.95839792e-01  1.57870814e-01  3.55860367e-02 -4.01669055e-01\n",
      " -1.11996062e-01 -1.52261689e-01  9.41067636e-02  4.45515364e-02\n",
      "  2.51529604e-01 -6.11938117e-03 -1.03060797e-01 -1.86740518e-01\n",
      " -2.00652659e-01  1.95525631e-01  3.53652015e-02  2.05845281e-01\n",
      " -1.88711047e-01  4.62705418e-02 -2.86314398e-01  2.59992659e-01\n",
      " -1.58450931e-01 -4.86966260e-02 -3.10343504e-01  2.20293120e-01\n",
      "  3.24421227e-01 -3.83507609e-02 -1.36116683e-01  1.86484512e-02\n",
      "  2.52862662e-01 -2.84274161e-01  6.55230805e-02 -7.86645710e-02\n",
      "  2.48518497e-01  4.84138206e-02 -4.71031815e-01 -2.56308839e-02\n",
      "  6.88094506e-03 -6.46869689e-02  7.51150399e-02 -1.84818909e-01\n",
      "  2.95323193e-01  1.70648649e-01 -3.50355387e-01  1.74989179e-01\n",
      " -2.38611251e-02  1.19894400e-01 -4.99120392e-02 -1.88966632e-01\n",
      "  4.78033684e-02  1.24054933e-02 -1.17373496e-01 -1.13962993e-01\n",
      " -1.50268942e-01  1.46188155e-01 -2.73598164e-01 -3.84346694e-01\n",
      " -2.41419807e-01  2.70689130e-01 -5.08786261e-01  8.19893256e-02\n",
      "  2.99139798e-01 -1.78011045e-01  3.29936817e-02 -9.85633880e-02\n",
      "  2.55957365e-01 -2.21884400e-01  1.51820034e-01 -1.74267262e-01\n",
      " -5.16205132e-02 -2.24521197e-02 -4.98086885e-02 -2.03004822e-01\n",
      "  2.32287366e-02 -3.91208716e-02  5.44574857e-02 -1.66236237e-01\n",
      "  3.03840637e-01 -1.58242837e-01  1.55036837e-01 -4.30629730e-01\n",
      "  1.33514866e-01 -1.13212608e-01  5.08300327e-02 -2.96761870e-01\n",
      " -8.95497575e-02 -3.50041062e-01  5.68067990e-02  3.23467970e-01]\n",
      "일요일 = 월요일\t 0.638277\n",
      "안성기 = 배우\t 0.5586097\n",
      "대기업 = 삼성\t 0.5344158\n",
      "일요일 != 삼성\t 0.21233039\n",
      "히어로 != 삼성\t 0.14928576\n",
      "[('장미희', 0.7232547402381897), ('씨야', 0.7122513055801392), ('이은우', 0.6866679191589355), ('김정학', 0.6859705448150635), ('박신양', 0.6815844178199768)]\n",
      "[('X맨', 0.6693664193153381), ('더 울버린', 0.663064181804657), ('엑스맨', 0.6570957899093628), ('캐리비안의 해적', 0.6490655541419983), ('비포 선셋', 0.6475238800048828)]\n"
     ]
    }
   ],
   "source": [
    "# 위에서 저장한 모델 파일(nvmc.model) 활용 예제\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# 모델 로딩\n",
    "model = Word2Vec.load('nvmc.model')\n",
    "print(\"corpus_total_words: \", model.corpus_total_words)\n",
    "\n",
    "# '사랑'이란 단어로 생성한 단어 임베딩 벡터\n",
    "print('사랑: ', model.wv['사랑'])\n",
    "\n",
    "# 단어 유사도 계산\n",
    "print(\"일요일 = 월요일\\t\", model.wv.similarity(w1='일요일', w2='월요일'))\n",
    "print(\"안성기 = 배우\\t\", model.wv.similarity(w1='안성기', w2='배우'))\n",
    "print(\"대기업 = 삼성\\t\", model.wv.similarity(w1='대기업', w2='삼성'))\n",
    "print(\"일요일 != 삼성\\t\", model.wv.similarity(w1='일요일', w2='삼성'))\n",
    "print(\"히어로 != 삼성\\t\", model.wv.similarity(w1='히어로', w2='삼성'))\n",
    "\n",
    "# 가장 유사한 단어 추출\n",
    "print(model.wv.most_similar(\"안성기\", topn=5))\n",
    "print(model.wv.most_similar(\"시리즈\", topn=5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
